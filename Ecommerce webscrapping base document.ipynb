{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73428dd",
   "metadata": {},
   "source": [
    "### <center> WEBSCRAPPING E-COMMERCE WEBSITE USING PYTHON AND SELENIUM </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40eab702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding driver path (for the first time is enough)\n",
    "import os\n",
    "os.environ['PATH']+=r'C:\\selenium_drivers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main program - to scrape products\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#creating a empty dataframe with columns\n",
    "df = pd.DataFrame(columns=['Title', 'Name', 'Rating', 'Rating_Nos', 'Price', 'Discount', 'Distress', 'Waist Rise', 'Fade', 'Shade', 'Fit', 'Length', 'Waistband', 'Stretch'])\n",
    "\n",
    "#first page link\n",
    "main_page = \"https://\"#ecommerce webiste product page link\"/women-jeans\"\n",
    "\n",
    "driver.implicitly_wait(2)\n",
    "\n",
    "driver.get(main_page)\n",
    "\n",
    "#will loop 3 pages...change the upperbound of range to scrape more pages\n",
    "for i in range(0,3):\n",
    "    #getting all the products in the all product containers of page\n",
    "    x=driver.find_element(By.CSS_SELECTOR,'ul[class=\"results-base\"]')\n",
    "    \n",
    "    #list of all the a tags of products\n",
    "    products =x.find_elements(By.TAG_NAME,\"a\")\n",
    "    \n",
    "    #list of only the href (link) part of a tags\n",
    "    product_links=[]\n",
    "    for product in products:\n",
    "        product_links.append(product.get_attribute('href'))\n",
    "    \n",
    "    #passing to a fuction to loop through the product links and scrape the data\n",
    "    prod_loop(product_links)\n",
    "    \n",
    "    #getting back to the last main page\n",
    "    driver.get(main_page)\n",
    "    \n",
    "    #reassigning the main page to return again for moving to the next page\n",
    "    main_page = driver.find_element(By.CSS_SELECTOR,'a[rel=\"next\"]').get_attribute('href')\n",
    "    \n",
    "    #going to next page\n",
    "    driver.find_element(By.CSS_SELECTOR,'a[rel=\"next\"]').click()\n",
    "    \n",
    "df.to_csv('product_details.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625ccdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scrape and store data\n",
    "\n",
    "def prod_loop(product_links):\n",
    "\n",
    "    #loop for all the product details scraping from one single page\n",
    "\n",
    "    for i in range(7, len(product_links)):#len(product_links)'\n",
    "       \n",
    "       \n",
    "    #getting inside the product page\n",
    "        try:\n",
    "            driver.get(product_links[i])\n",
    "        except e:\n",
    "            print(e)\n",
    "            \n",
    "       \n",
    "        \n",
    "        #wait till the page loads\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        #getting the basic product details\n",
    "\n",
    "        product_detail = driver.find_element(By.CSS_SELECTOR,'div[class=\"pdp-price-info\"]')\n",
    "        p_title = product_detail.find_element(By.CSS_SELECTOR, 'h1[class=\"pdp-title\"]').get_attribute('innerHTML')\n",
    "        p_name = product_detail.find_element(By.CSS_SELECTOR, 'h1[class=\"pdp-name\"]').get_attribute('innerHTML')\n",
    "\n",
    "        try:\n",
    "            p_rating = product_detail.find_element(By.CSS_SELECTOR, 'div[class=\"index-overallRating\"]').find_element(By.TAG_NAME, 'div').get_attribute('innerHTML')\n",
    "            \n",
    "        except:\n",
    "            p_rating = np.NAN\n",
    "            \n",
    "        try:\n",
    "            p_rating_numbers = product_detail.find_element(By.CSS_SELECTOR, 'div[class=\"index-ratingsCount\"]').get_attribute('innerText')\n",
    "        except:\n",
    "            p_rating_numbers = np.NAN\n",
    "            \n",
    "\n",
    "        try:\n",
    "            p_price = product_detail.find_element(By.CSS_SELECTOR,'span[class=\"pdp-price\"]').get_attribute('innerText')\n",
    "            \n",
    "        except:\n",
    "            p_price = np.NAN\n",
    "\n",
    "            \n",
    "        try:\n",
    "            p_discount = product_detail.find_elements(By.CSS_SELECTOR,'span[class=\"pdp-mrp-verbiage-amt\"]')[1].get_attribute('innerHTML')\n",
    "           \n",
    "        except:\n",
    "            p_discount = np.NAN\n",
    "\n",
    "\n",
    "        #creating a dictionary and updating the basic details\n",
    "        details = dict()\n",
    "        details.update({'Title':p_title,'Name':p_name,'Rating':p_rating,'Rating_Nos':p_rating_numbers,'Price':p_price,'Discount':p_discount})\n",
    "\n",
    "        \n",
    "        #show more button click\n",
    "        try:\n",
    "            driver.find_element(By.CSS_SELECTOR,'div[class=\"index-showMoreText\"]').click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #all prod desc\n",
    "        tables = driver.find_elements(By.CSS_SELECTOR, 'div[class=\"index-tableContainer\"]')\n",
    "\n",
    "        #prod desc table headings and values\n",
    "        headings_text =[]\n",
    "        values_text =[]\n",
    "\n",
    "        for table in tables:\n",
    "            headings = table.find_elements(By.CSS_SELECTOR, 'div[class=\"index-rowKey\"]')\n",
    "            for heading in headings:\n",
    "                headings_text.append(heading.get_attribute('innerHTML'))\n",
    "            values = table.find_elements(By.CSS_SELECTOR, 'div[class=\"index-rowValue\"]')\n",
    "            for value in values:\n",
    "                values_text.append(value.get_attribute('innerHTML'))\n",
    "\n",
    "        #updating the dictionary with desc table values\n",
    "        for i in range(0,len(headings_text)):\n",
    "            details.update({headings_text[i]:values_text[i]})\n",
    "        \n",
    "        \n",
    "        \n",
    "        global df\n",
    "        #appending the dataframe with the dictionary values - note: for unmatched column names the values will be null\n",
    "        df=df.append(details,ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7025caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
